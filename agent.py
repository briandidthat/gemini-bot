from datetime import datetime
from typing import Dict, Optional
import pathlib
import requests

from google import genai

from exception import DoneForTheDayException
from logger import gemini_agent_logger
from models import Chat, File


class GeminiAgent:
    """
    Agent responsible for managing chat interactions with a multimodal model.

    Parameters:
        api_key (str): The API key for Google Generative AI.
            (https://developers.google.com/generative-ai/docs/get-started)
        model_name (str): The name of the generative model to use.
        daily_limit (int): The maximum number of requests allowed per day.

    Attributes:
        client (genai.Client): The client used to make requests to Google GenAI.
        model (str): The current generative model being used.
        daily_limit (int): The maximum number of requests allowed per day.
        chats (Dict[str, Chat]): A dictionary storing chat sessions for users.
        request_count (int): The current count of requests made.
    """

    def __init__(self, api_key: str, model_name: str, daily_limit: int) -> None:
        """Initialize the Gemini Agent with API key and configuration."""
        self.client: genai.Client = genai.Client(api_key=api_key)
        self.model: str = model_name
        self.daily_limit: int = daily_limit
        self.chats: Dict[str, Chat] = {}
        self.request_count: int = 0

    # Public Methods

    def get_chat_for_user(self, username: str) -> Optional[Chat]:
        """
        Retrieve the chat session for a specific user.

        Args:
            username: The name of the user.

        Returns:
            The user's chat session or None if not found.
        """
        return self.chats.get(username, None)

    def set_model(self, model_name: str) -> None:
        """
        Set a new generative model.

        Args:
            model_name: The name of the model to use.
        """
        self.model = model_name
        gemini_agent_logger.info(
            "A new model has been set.", extra=dict(model_name=model_name)
        )

    def store_chat(self, chat: Chat) -> None:
        """
        Store a chat session.

        Args:
            chat: The chat to store.
        """
        if chat:
            self.chats[chat.username] = chat
            gemini_agent_logger.info(
                "A new chat has been stored.", extra=chat.serialize()
            )

    def remove_chat(self, username: str) -> None:
        """
        Remove a chat session for a specific user.

        Args:
            username: The name of the user whose chat to remove.
        """
        chat = self.chats.pop(username, None)
        if chat:
            gemini_agent_logger.info(
                "Chat history has been deleted.",
                extra=dict(chat_info=chat.serialize()),
            )

    def remove_all_chats(self) -> None:
        """Remove all chat sessions."""
        chats_count = len(self.chats)
        self.chats.clear()
        gemini_agent_logger.info(
            "All chats have been erased.", extra={"chats_deleted": chats_count}
        )

    async def process_chat_prompt(self, username: str, prompt: str) -> str:
        """
        Send a chat interaction for a specific user.

        Args:
            username: The name of the user.
            prompt: The message to send within the chat.

        Returns:
            The text response generated by the chat model.

        Raises:
            DoneForTheDayException: If the daily request limit would be exceeded.
        """
        self._validate_request_limit()

        # Fetch existing chat data
        chat = self.get_chat_for_user(username)

        # If chat is None, then the user has no chat history, so we will create a new chat
        if chat is None:
            # Start a new chat if no chat history exists for the user
            chat_session = self.client.chats.create(model=self.model)
            chat = Chat(username, chat_session, datetime.now(), None)
            self.store_chat(chat)

        response = chat.session.send_message(prompt)
        # set the last message time to now
        chat.last_message = datetime.now()

        # log the chat message sent
        gemini_agent_logger.info(
            "Chat message sent.",
            extra=dict(username=username, prompt=prompt, chat=chat.serialize()),
        )

        # increment request count
        self._increment_request_count()
        return response.text

    async def process_file_prompt(
        self,
        username: str,
        prompt: str,
        file: File,
    ) -> str:
        """
        Send a chat interaction with a file for a specific user.

        Args:
            username: The name of the user.
            prompt: The message to send within the chat.
            file: The file to be processed by the model.

        Returns:
            The text response generated by the chat model.

        Raises:
            DoneForTheDayException: If the daily request limit would be exceeded.
        """
        self._validate_request_limit()

        # generate the response using the file and text prompt
        response = await self.client.aio.models.generate_content(
            model=self.model, contents=[file.content, prompt]
        )

        # close the file since we don't need it anymore
        file.close()

        gemini_agent_logger.info(
            "Content generated using file and text prompt.",
            extra=dict(
                username=username,
                prompt=prompt,
                filename=file.name,
                responseLength=len(response.text),
            ),
        )

        self._increment_request_count()
        return response.text

    # Private Methods

    def _increment_request_count(self) -> None:
        """Increment the request counter."""
        self.request_count += 1

    def _upload_file(
        self, file_location: str, file_name: str, content_type: str
    ) -> File:
        """Upload a file to the model.

        Args:
            file_name: The name of the file to upload.
            content_type: The MIME type of the file.

        Returns:
            A File object containing the uploaded file information.
        """
        response = requests.get(file_location)
        pathlib.Path(file_name).write_text(response.text)

        file = self.client.files.upload(file=file_name)
        return File(file_name, file, content_type)

    def _delete_file(self, file_name: str) -> None:
        """Delete an uploaded file.

        Args:
            file_name: The name of the file to delete.
        """
        self.client.files.delete(name=file_name)
        gemini_agent_logger.info(
            "File has been deleted.", extra=dict(file_name=file_name)
        )
        # remove the file from the local directory
        file_path = pathlib.Path(file_name)
        if file_path.exists():
            file_path.unlink()
            gemini_agent_logger.info(
                "File has been removed from local storage.",
                extra=dict(file_name=file_name),
            )
        else:
            gemini_agent_logger.warning(
                "File not found in local storage.",
                extra=dict(file_name=file_name),
            )

    def _validate_request_limit(self) -> None:
        """
        Check if the request limit will be exceeded.

        Raises:
            DoneForTheDayException: If the daily limit has been reached.
        """
        if self.request_count + 1 > self.daily_limit:
            raise DoneForTheDayException(
                message="Daily limit has been reached.", type=type(ValueError).__name__
            )
